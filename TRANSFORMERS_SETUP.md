# ü§ñ Transformers.js - IA Local en React Native

## ‚úÖ Qu√© es?

**Transformers.js** permite correr modelos de IA (como GPT) directamente en tu dispositivo m√≥vil, sin internet, 100% gratis.

---

## üì¶ Instalaci√≥n

```bash
npm install @xenova/transformers
```

**Nota:** Requiere development build (como ML Kit)

---

## üß† Modelos Recomendados para Extracci√≥n M√©dica

### Opci√≥n 1: **Flan-T5-Small** (77MB)
- **Uso:** Question-answering, extracci√≥n de informaci√≥n
- **Velocidad:** ~2-5 segundos
- **Precisi√≥n:** Buena para texto estructurado
- **Ideal para:** Recetas m√©dicas simples

### Opci√≥n 2: **DistilGPT-2** (353MB)
- **Uso:** Generaci√≥n y comprensi√≥n de texto
- **Velocidad:** ~3-7 segundos
- **Precisi√≥n:** Muy buena
- **Ideal para:** Textos m√©dicos complejos

### Opci√≥n 3: **BERT-Base-Multilingual** (177MB)
- **Uso:** Extracci√≥n de entidades (NER)
- **Velocidad:** ~1-3 segundos
- **Precisi√≥n:** Excelente para espa√±ol
- **Ideal para:** Nombres de medicamentos, dosis

---

## üöÄ Implementaci√≥n en Photolarm

### 1. Crear `TransformersExtractorService`

```typescript
// src/services/extractor.service.transformers.ts
import { pipeline } from '@xenova/transformers';

export class TransformersExtractorService implements IExtractorService {
  private extractor: any = null;
  private isLoaded = false;

  async loadModel() {
    if (this.isLoaded) return;
    
    console.log('Loading Transformers model...');
    this.extractor = await pipeline('text2text-generation', 'Xenova/flan-t5-small');
    this.isLoaded = true;
    console.log('Model loaded!');
  }

  async extractPlans(text: string, context?: ExtractorContext): Promise<DocumentParse> {
    await this.loadModel();

    // Create prompt for the model
    const prompt = `Extract medication information from this medical text in JSON format.
Text: "${text}"

Extract:
1. Medication name
2. Dosage (mg, ml, tablets)
3. Frequency (times per day or every X hours)
4. Duration (number of days)

Format: {"medications": [{"name": "...", "dosage": "...", "frequency": "...", "duration_days": ...}]}`;

    // Run model
    const result = await this.extractor(prompt, {
      max_new_tokens: 200,
      temperature: 0.3,
    });

    // Parse model output
    try {
      const extracted = JSON.parse(result[0].generated_text);
      
      // Convert to DocumentParse format
      const plans = extracted.medications.map((med: any) => ({
        id: `med_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        mode: 'flexible' as const,
        domain: 'medication' as const,
        category: 'health' as const,
        confidence: 0.75,
        evidence: text,
        flexible_pattern: {
          items: [{
            interval_hours: this.parseFrequency(med.frequency),
            duration_days: med.duration_days || 7,
            title: `${med.name} ${med.dosage}`,
            description: `Tomar ${med.dosage} ${med.frequency}`,
          }],
        },
      }));

      return {
        success: plans.length > 0,
        plans,
        raw_text: text,
        metadata: {
          extraction_model: 'transformers-flan-t5-small',
          extraction_timestamp: new Date().toISOString(),
        },
      };
    } catch (error) {
      console.error('Failed to parse model output:', error);
      return {
        success: false,
        plans: [],
        raw_text: text,
        errors: ['Model parsing failed'],
        metadata: {
          extraction_model: 'transformers-flan-t5-small',
          extraction_timestamp: new Date().toISOString(),
        },
      };
    }
  }

  private parseFrequency(frequency: string): number {
    // "2 times per day" -> 12 hours
    // "every 8 hours" -> 8 hours
    const timesMatch = frequency.match(/(\d+)\s+times?\s+per\s+day/i);
    if (timesMatch) {
      return Math.floor(24 / parseInt(timesMatch[1]));
    }
    
    const hoursMatch = frequency.match(/every\s+(\d+)\s+hours?/i);
    if (hoursMatch) {
      return parseInt(hoursMatch[1]);
    }
    
    return 24; // Default: once daily
  }

  validate(parse: DocumentParse): string[] {
    return parse.success ? [] : ['Extraction failed'];
  }
}
```

### 2. Actualizar `CameraScreen.tsx`

```typescript
import { TransformersExtractorService } from '@/services/extractor.service.transformers';

// En CameraScreen:
const extractorService = new TransformersExtractorService();
```

---

## ‚öôÔ∏è Configuraci√≥n

### Development Build

Transformers.js necesita m√≥dulos nativos para ONNX Runtime:

```bash
eas build --profile development --platform android
```

---

## üìä Comparaci√≥n de Modelos

| Modelo | Tama√±o | Velocidad | Precisi√≥n | Idiomas |
|---|---|---|---|---|
| **Flan-T5-Small** | 77MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Multi |
| **DistilGPT-2** | 353MB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | EN |
| **BERT-Multilingual** | 177MB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Multi |

---

## üéØ Pros vs Cons

### ‚úÖ Ventajas
- 100% gratis, sin l√≠mites
- Funciona offline
- Privacidad total
- No requiere API keys
- Despu√©s de descarga inicial, muy r√°pido

### ‚ùå Desventajas
- Primera descarga (~77-350MB seg√∫n modelo)
- Menos preciso que GPT-4
- Consume bater√≠a al procesar
- Requiere development build

---

## üöÄ Build y Deploy

1. Instalar dependencia:
```bash
npm install @xenova/transformers
```

2. Hacer build:
```bash
eas build --profile development --platform android
```

3. Primera vez app descargar√° el modelo (~10 segundos)

4. Despu√©s de eso, todo es instant√°neo y offline

---

## üîç Testing

```typescript
const service = new TransformersExtractorService();

const text = `
Paracetamol 500 miligramos
1 tableta. V√≠a oral. 2 veces al d√≠a. Por 30 d√≠as.
`;

const result = await service.extractPlans(text);
console.log(result);
// Output: 1 plan de Paracetamol 500mg cada 12h por 30 d√≠as
```

---

## üí° Tips

1. **Cache el modelo:** La primera carga tarda, luego es r√°pido
2. **Usa Flan-T5-Small:** Mejor balance tama√±o/precisi√≥n
3. **Prueba con texto real:** Los modelos aprenden de ejemplos
4. **Ajusta temperatura:** M√°s bajo = m√°s consistente (0.1-0.5)

---

## üìö Recursos

- **Transformers.js:** https://huggingface.co/docs/transformers.js
- **Modelos disponibles:** https://huggingface.co/models?library=transformers.js
- **React Native ONNX:** https://onnxruntime.ai/docs/get-started/with-javascript.html

---

**√öltima actualizaci√≥n:** 9 de enero de 2026
**Recomendaci√≥n:** Ideal para MVP, luego migrar a GPT-4 si escala
